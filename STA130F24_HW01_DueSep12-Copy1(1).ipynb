{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaad910f",
   "metadata": {},
   "source": [
    "# STA130 Week 01 Homework \n",
    "\n",
    "Please see the course [wiki-textbook](https://github.com/pointOfive/stat130chat130/wiki) for the list of topics covered in this homework assignment, and a list of topics that might appear during ChatBot conversations which are \"out of scope\" for the purposes of this homework assignment (and hence can be safely ignored if encountered)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aede3d7",
   "metadata": {},
   "source": [
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Introduction</u></summary>\n",
    "\n",
    "### Introduction\n",
    "    \n",
    "A reasonable characterization of STA130 Homework is that it simply defines a weekly reading comprehension assignment. \n",
    "Indeed, STA130 Homework essentially boils down to completing various understanding confirmation exercises oriented around coding and writing tasks.\n",
    "However, rather than reading a textbook, STA130 Homework is based on ChatBots so students can interactively follow up to clarify questions or confusion that they may still have regarding learning objective assignments.\n",
    "\n",
    "> Communication is a fundamental skill underlying statistics and data science, so STA130 Homework based on ChatBots helps practice effective two-way communication as part of a \"realistic\" dialogue activity supporting underlying conceptual understanding building. \n",
    "\n",
    "It will likely become increasingly tempting to rely on ChatBots to \"do the work for you\". But when you find yourself frustrated with a ChatBots inability to give you the results you're looking for, this is a \"hint\" that you've become overreliant on the ChatBots. Your objective should not be to have ChatBots \"do the work for you\", but to use ChatBots to help you build your understanding so you can efficiently leverage ChatBots (and other resources) to help you work more efficiently.<br><br>\n",
    "\n",
    "</details>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Instructions</u></summary>\n",
    "\n",
    "### Instructions\n",
    "    \n",
    "1. Code and write all your answers (for both the \"Prelecture\" and \"Postlecture\" HW) in a python notebook (in code and markdown cells) \n",
    "    \n",
    "> It is *suggested but not mandatory* that you complete the \"Prelecture\" HW prior to the Monday LEC since (a) all HW is due at the same time; but, (b) completing some of the HW early will mean better readiness for LEC and less of a \"procrastentation cruch\" towards the end of the week...\n",
    "    \n",
    "2. Paste summaries of your ChatBot sessions (including link(s) to chat log histories if you're using ChatGPT) within your notebook\n",
    "    \n",
    "> Create summaries of your ChatBot sessions by using concluding prompts such as \"Please provide a summary of our exchanges here so I can submit them as a record of our interactions as part of a homework assignment\" or, \"Please provide me with the final working verson of the code that we created together\"\n",
    "    \n",
    "3. Save your python jupyter notebook in your own account and \"repo\" on [github.com](github.com) and submit a link to that notebook though Quercus for assignment marking<br><br>\n",
    "\n",
    "</details>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Prompt Engineering?</u></summary>\n",
    "\n",
    "### Prompt Engineering?    \n",
    "    \n",
    "The questions (as copy-pasted prompts) are designed to initialize appropriate ChatBot conversations which can be explored in the manner of an interactive and dynamic textbook; but, it is nonetheless **strongly recommendated** that your rephrase the questions in a way that you find natural to ensure a clear understanding of the question. Given sensible prompts the represent a question well, the two primary challenges observed to arise from ChatBots are \n",
    "\n",
    "1. conversations going beyond the intended scope of the material addressed by the question; and, \n",
    "2. unrecoverable confusion as a result of sequential layers logial inquiry that cannot be resolved. \n",
    "\n",
    "In the case of the former (1), adding constraints specifying the limits of considerations of interest tends to be helpful; whereas, the latter (2) is often the result of initial prompting that leads to poor developments in navigating the material, which are likely just best resolve by a \"hard reset\" with a new initial approach to prompting.  Indeed, this is exactly the behavior [hardcoded into copilot](https://answers.microsoft.com/en-us/bing/forum/all/is-this-even-normal/0b6dcab3-7d6c-4373-8efe-d74158af3c00)...\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77293b06",
   "metadata": {},
   "source": [
    "\n",
    "### Marking Rubric (which may award partial credit) \n",
    "\n",
    "- [0.1 points]: All relevant ChatBot summaries [including link(s) to chat log histories if you're using ChatGPT] are reported within the notebook\n",
    "- [0.2 points]: Reasonable well-written general definitions for Question \"2.2\"\n",
    "- [0.3 points]: Demonstrated understanding regarding Question \"4\"\n",
    "<!-- - [0.2 points]: A sensible justification for the choice in Question \"7.4\" -->\n",
    "- [0.4 points]: Requested assessment of ChatBot versus google performance in Question \"8.3\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8cc949",
   "metadata": {},
   "source": [
    "## \"Prelecture\" HW [*completion prior to next LEC is suggested but not mandatory*]\n",
    "\n",
    "#### 1. Pick one of the datasets from the ChatBot session(s) of the **TUT demo** (or from your own ChatBot session if you wish) and use the code produced through the ChatBot interactions to import the data and confirm that the dataset has missing values<br>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "\n",
    "> If your TA has not shared a relevant ChatBot session from their **TUT demo** through a piazza post and a Quercus announcement, the **TUT notebook** has links to example ChatBot sessions that you can use; or, ...\n",
    "> \n",
    "> ```python\n",
    "> # feel free to just use the following if you prefer...\n",
    "> import pandas as pd\n",
    "> url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "> df = pd.read_csv(url)\n",
    "> df.isna().sum()\n",
    "> ```\n",
    "    \n",
    "</details>\n",
    "\n",
    "#### 2. Start a new ChatBot session with an initial prompt introducing the dataset you're using and request help to determine how many columns and rows of data a `pandas` DataFrame has, and then\n",
    "\n",
    "1. use code provided in your ChatBot session to print out the number of rows and columns of the dataset; and,  \n",
    "2. write your own general definitions of the meaning of \"observations\" and \"variables\" based on asking the ChatBot to explain these terms in the context of your dataset<br>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "\n",
    "> A good initial prompt to start would be be something like\n",
    "> - \"I've downloaded a dataset about characters from animal crossings (from https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv), and I'd like to know what columns of information I have and how much data I have\"\n",
    "> \n",
    "> You can further reduce the scope of your inquiry with if needed with something like\n",
    "> - \"I've already downloaded the data and want to understand the size (or dimensions) of the dataset to start with\"\n",
    "> \n",
    "> *Some ChatBots can upload your data and do this for you; but, extended usage of this feature [likely requires a paid subscription](https://github.com/pointOfive/stat130chat130/blob/main/CHATLOG/wk1/GPT/SLS/00006_gpt3p5_LoadDataPaywall.md); and, anyway, you need to run the code yourself rather than having a ChatBot do that for you; and, for STA130 we don't want a ChatBot to just do the analysis for us; rather, we instead want ChatBots to help us understand the steps we need to take to analyze the data; so,* **you DO NOT need to purchase an upgraded version of any ChatBots**\n",
    "> - Free-tier level ChatBots like [GPT4o-mini](https://chat.openai.com/) or [Copilot](https://copilot.microsoft.com/) (which is partially based on [ChatGPT4.0](https://chat.openai.com/), and which you have access to through your UofT account) are sufficiently sophisticated and perfectly appropriate for the STA130 course\n",
    "    \n",
    "</details>\n",
    "\n",
    "#### 3. Ask the ChatBot how you can provide simple summaries of the columns in the dataset and use the suggested code to provide these summaries for your dataset<br>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "\n",
    "> Use your ChatBot session to help you create working examples of using  `df.describe()` and `df['column'].value_counts()` for your dataset (although note that the `.value_counts()` method is not really meant to be used for numeric variables, so if you dataset has only numeric variables, `.value_counts()` might not be particularly informative...)\n",
    ">\n",
    "> #### ChatBot Response Scope \n",
    ">     \n",
    "> If prompts are not sufficiently focused you will likely get overly broad responses from the ChatBot, but you can always respond with subsequent refinement requests to appropriately limit the scope of the ChatBot responses to focus on addressing your actual content targets; so, \n",
    "> - an initially very general inquiry like, \"I need help analyzing my data\" will likely result in a ChatBot response suggesting a wide variety of approaches and techniques for summarizing your dataset; but, re-prompting the ChatBot with something like, \"What's the simplest form of summarization of this dataset that I could do and how do I do it in Python?\" or suggesting guidance using the specific summarization methods requested above will helpfully re-orient the ChatBot to your specific interests and needs\n",
    "> \n",
    "> #### Jupyter Notebook Hints\n",
    "> \n",
    "> Jupyter notebook printouts usaully don't show all of the data (when there's too much to show, like if `df.describe()` includes results for many columns), but the printouts just show enough of the data to give an idea of what the results are which is all we're looking for at the moment\n",
    "> \n",
    "> - Consider dividing the code that ChatBot provides you into different jupyter notebook cells so that each cell concludes with a key printed result; the last line of code in a jupyter notebook cell will automatically print out in a formatted manner, so replacing something like `print(df.head())` with `df.head()` as the last line of a cell provides a sensible way to organize your code\n",
    "> - The printout suggestions above are demonstrated in `STA130F24_CourseProject.ipynb` if looking at an example would be helpful to understand what they're getting at...\n",
    "    \n",
    "</details>\n",
    "                \n",
    "#### 4. If the dataset you're using has (a) non-numeric variables and (b) missing values in numeric variables, explain (perhaps using help from a ChatBot if needed) the discrepancies between size of the dataset given by `df.shape` and what is reported by `df.describe()` with respect to (a) the number of columns it analyzes and (b) the values it reports in the \"count\" column<br>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "\n",
    "> If the dataset you're using does not have (a) non-numeric variables and (b) missing values in numeric variables (e.g., the `\"villagers.csv\"` example above has only a single numeric variable `row_n` which has no missing values), instead download and use the [https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv](https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv)\" data to answer this question  \n",
    ">\n",
    "> In (a) above, the \"columns it analyzes\" refers to the columns of the output of `df.describe()` which will only include \"numeric\" columns by default, but you can can see the names of all the columns in a dataset using `df.columns`; and, make sure `df.shape` is refering to the dataset you think it is... if you've loaded a different dataset it might not have been called `df`(!)\n",
    ">\n",
    "> **If you get any errors (for example related to column names), copy and paste them as a response to the ChatBot, and see if it can help you resove them by adding the suggested adjustments to your code and then reruning all your code to see if the changes have fixed the problem (and repeat this process as needed until the problems have been resolved).**\n",
    "    \n",
    "</details>\n",
    "    \n",
    "#### 5. Use your ChatBot session to help understand the difference between the following and then provide your own paraphrasing summarization of that difference\n",
    "\n",
    "- an \"attribute\", such as `df.shape` which does not end with `()`\n",
    "- and a \"method\", such as `df.describe()` which does end with `()` \n",
    "   \n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "\n",
    "> The fact that a \"method\" such as `df.describe()` ends with `()` suggests that \"methods\" are essentially something that we would call a \"function\" in programming language terminology; but, without getting too technical or \"in the weeds\", it might also be worth considering that we could also contrast what the difference is between a \"function\" in a programming language versus a \"function\" in mathematics...  \n",
    "    \n",
    "</details><br><br>\n",
    "\n",
    "***Don't forget to ask for summaries of your ChatBot session(s) and paste these into your homework notebook (including link(s) to chat log histories if you're using ChatGPT)!***<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea57fbf",
   "metadata": {},
   "source": [
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Continue now...?</u></summary>\n",
    "\n",
    "### Prelecture VS Postlecture HW\n",
    "    \n",
    "Feel free to work on the \"Postlecture\" HW below if you're making good progress and want to continue: in this case this is particularly reasonable as questions \"6\" and \"7\" below directly follow up and extend the \"Prelecture\" HW questions\n",
    "\n",
    "*The benefits of continue would are that (a) it might be fun to try to tackle the challenge of working through some problems without additional preparation or guidance; and (b) this is a very valable skill to be comfortable with; and (c) it will let you build experience interacting with ChatBots (and beginning to understand their strengths and limitations in this regard)... it's good to have sense of when using a ChatBot is the best way to figure something out, or if another approach (such as course provided resources or a plain old websearch for the right resourse) would be more effective*\n",
    "    \n",
    "</details>    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d258e0",
   "metadata": {},
   "source": [
    "## \"Postlecture\" HW [*submission along with \"Prelecture\" HW is due prior to next TUT*]\n",
    "\n",
    "#### 6. The `df.describe()` method provides the 'count', 'mean', 'std', 'min', '25%', '50%', '75%', and 'max' summary statistics for each variable it analyzes. Give the definitions (perhaps using help from the ChatBot if needed) of each of these summary statistics<br>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "\n",
    "> The answers here actually make it obvious why these can only be calculated for numeric variables in a dataset, which should help explain the answer to \"4(a)\" and \"4(b)\" above\n",
    ">   \n",
    "> Also notice that when `df.describe()` is used missing values are not explicitly removed, but `df.describe()`  provides answers anyway. Is it clear what `df.describe()` does with the data in each columns it analyzes if there is missing data in the column in question? \n",
    ">\n",
    "> The next questions addresses removing rows or columns from a dataset in order to explicitly remove the presense of any missingness in the dataset (assuming we're not going to fill in any missing data values using any missing data imputation methods, which are beyond the scope of STA130); so, the behavior of `df.describe()` hints that explicitly removing missing may not always be necessary; but, the concern, though, is that not all methods may be able to handle missing data the way `df.describe()` does...\n",
    "    \n",
    "</details>\n",
    "\n",
    "#### 7. Missing data can be considered \"across rows\" or \"down columns\".  Consider how `df.dropna()` or `del df['col']` should be applied to most efficiently use the available non-missing data in your dataset and briefly answer the following questions in your own words\n",
    "\n",
    "1. Provide an example of a \"use case\" in which using `df.dropna()` might be peferred over using `del df['col']`<br><br>\n",
    "    \n",
    "2. Provide an example of \"the opposite use case\" in which using `del df['col']` might be preferred over using `df.dropna()` <br><br>\n",
    "    \n",
    "3. Discuss why applying `del df['col']` before `df.dropna()` when both are used together could be important<br><br>\n",
    "    \n",
    "4. Remove all missing data from one of the datasets you're considering using some combination of `del df['col']` and/or `df.dropna()` and give a justification for your approach, including a \"before and after\" report of the results of your approach for your dataset.<br><br>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "\n",
    "> Start a new ChatBot session **[but remember to first ask your ChatBot for summaries of your current session and perhaps coding results (so you can supply these in the homework as requested)]**, since your last ChatBot session has likely gotten quite long and has covered a lot of material at this point \n",
    "> - It can sometimes be helpful to reset ChatBot sessions to refocus them on the topics of inquiry without too much backlog history that might unintentionally bias things in certain directions and, of course, you can always re-introduce material from earlier conversations as it's relevant, such as for answering \"D\" based on reintroducing and updating code you made in a previous ChatBot session.  \n",
    "> \n",
    "> #### ChatBot Scope Guidance\n",
    "> \n",
    "> - This question is not interested in the general benefits of imputing missing data, or the general benefits of using `df.dropna()` and/or `del df['col']` to remove missing data, just how to most efficiently remove missing data if a user chooses to do so\n",
    "> \n",
    "> - More sophisticated analyses for \"filling in\" rather than removing missing data (as considered here) are possible (based on making assumptions about missing data and using specific imputation methods or models) but these are \"beyond the scope\" of this homework assignment so this topics can be safely ignored for now\n",
    "> \n",
    "> #### ChatBot Code Troubleshooting\n",
    "> \n",
    "> A key issue to be aware of when asking ChatBots for help with something is that they are not running and checking code for correctess, and they often intertwine written instructions with code instructions; so, BEFORE YOU RUN ANY CODE provided by a ChatBot, you should check the following\n",
    "> \n",
    "> 1. If this code changes an object or data, are you sure you want to run this code?\n",
    "> 2. Can you easily \"undo\" the results of running code (e.g., from a copy `df_saved=df.copy()` or reloading the data) if running the code doesn't do what you want?\n",
    "> 3. Is the state of the data what is expected by the code? Or have the objects been updated and changed so they're no longer what the code expects them to be? \n",
    "> \n",
    "> #### If you get any `Python` errors, copy and paste them into the ChatBot prompt and see if it can help you resove them; but, keep in mind the final point above becasue the ChatBot might not be aware of the state of your objects relative to the code it's producing...\n",
    "\n",
    "</details><br>\n",
    "    \n",
    "#### 8. Give brief explanations in your own words for any requested answers to the questions below\n",
    "\n",
    "> This problem will guide you through exploring how to use a ChatBot to troubleshoot code using the \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\" data set \n",
    "> \n",
    "> To initialially constrain the scope of the reponses from your ChatBot, start a new ChatBot session with the following slight variation on the initial prompting approach from \"2\" above\n",
    "> - \"I am going to do some initial simple summary analyses on the titanic data set I've downloaded (https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv) which has some missing values, and I'd like to get your help understanding the code I'm using and the analysis it's performing\"\n",
    "        \n",
    "1. Use your ChatBot session to understand what `df.groupby(\"col1\")[\"col2\"].describe()` does and then demonstrate and explain this using a different example from the \"titanic\" data set other than what the ChatBot automatically provide for you\n",
    "    \n",
    "> If needed, you can help guide the ChatBot by showing it the code you've used to download the data **AND provide it with the names of the columns** using either a summary of the data with `df.describe()` or just `df.columns` as demonstrated [here](../CHATLOG/COP/00017_copilot_groupby.md)\n",
    "    \n",
    "2. Assuming you've not yet removed missing values in the manner of question \"7\" above, `df.describe()` would have different values in the `count` value for different data columns depending on the missingness present in the original data.  Why do these capture something fundamentally different from the values in the `count` that result from doing something like `df.groupby(\"col1\")[\"col2\"].describe()`?\n",
    "\n",
    "> Questions \"4\" and \"6\" above address how missing values are handled by `df.describe()` (which is reflected in the `count` output of this method); but, `count` in conjunction with `group_by` has another primary function that's more important than addressing missing values (although missing data could still play a role here).\n",
    "\n",
    "3. Intentionally introduce the following errors into your code and report your opinion as to whether it's easier to (a) work in a ChatBot session to fix the errors, or (b) use google to search for and fix errors: first share the errors you get in the ChatBot session and see if you can work with ChatBot to troubleshoot and fix the coding errors, and then see if you think a google search for the error provides the necessary toubleshooting help more quickly than ChatGPT<br><br>\n",
    "    \n",
    "    1. Forget to include `import pandas as pd` in your code \n",
    "       <br> \n",
    "       Use Kernel->Restart from the notebook menu to restart the jupyter notebook session unload imported libraries and start over so you can create this error\n",
    "       <br><br>\n",
    "       When python has an error, it sometimes provides a lot of \"stack trace\" output, but that's not usually very important for troubleshooting. For this problem for example, all you need to share with ChatGPT or search on google is `\"NameError: name 'pd' is not defined\"`<br><br>\n",
    "\n",
    "    2. Mistype \"titanic.csv\" as \"titanics.csv\"\n",
    "       <br> \n",
    "       If ChatBot troubleshooting is based on downloading the file, just replace the whole url with \"titanics.csv\" and try to troubleshoot the subsequent `FileNotFoundError: [Errno 2] No such file or directory: 'titanics.csv'` (assuming the file is indeed not present)\n",
    "       <br><br>\n",
    "       Explore introducing typos into a couple other parts of the url and note the slightly different errors this produces<br><br>\n",
    "      \n",
    "    3. Try to use a dataframe before it's been assigned into the variable\n",
    "       <br> \n",
    "       You can simulate this by just misnaming the variable. For example, if you should write `df.groupby(\"col1\")[\"col2\"].describe()` based on how you loaded the data, then instead write `DF.groupby(\"col1\")[\"col2\"].describe()`\n",
    "       <br><br>\n",
    "       Make sure you've fixed your file name so that's not the error any more<br><br>\n",
    "        \n",
    "    4. Forget one of the parentheses somewhere the code\n",
    "       <br>\n",
    "       For example, if the code should be `pd.read_csv(url)` the change it to `pd.read_csv(url`<br><br>\n",
    "        \n",
    "    5. Mistype one of the names of the chained functions with the code \n",
    "       <br>\n",
    "       For example, try something like `df.group_by(\"col1\")[\"col2\"].describe()` and `df.groupby(\"col1\")[\"col2\"].describle()`<br><br>\n",
    "        \n",
    "    6. Use a column name that's not in your data for the `groupby` and column selection \n",
    "       <br>\n",
    "       For example, try capitalizing the columns for example replacing \"sex\" with \"Sex\" in `titanic_df.groupby(\"sex\")[\"age\"].describe()`, and then instead introducing the same error of \"age\"<br><br>\n",
    "        \n",
    "    7. Forget to put the column name as a string in quotes for the `groupby` and column selection, and see if the ChatBot and google are still as helpful as they were for the previous question\n",
    "       <br>\n",
    "       For example, something like `titanic_df.groupby(sex)[\"age\"].describe()`, and then `titanic_df.groupby(\"sex\")[age].describe()`\n",
    "        \n",
    "#### 9. Have you reviewed the course [wiki-textbook](https://github.com/pointOfive/stat130chat130/wiki) and interacted with a ChatBot (or, if that wasn't sufficient, real people in the course piazza discussion board or TA office hours) to help you understand all the material in the tutorial and lecture that you didn't quite follow when you first saw it?<br>\n",
    "    \n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "\n",
    "> Just answering \"Yes\" or \"No\" or \"Somewhat\" or \"Mostly\" or whatever here is fine as this question isn't a part of the rubric; but, the midterm and final exams may ask questions that are based on the tutorial and lecture materials; and, your own skills will be limited by your familiarity with these materials (which will determine your ability to actually do actual things effectively with these skills... like the course project...)\n",
    "    \n",
    "</details>\n",
    "    \n",
    "***Don't forget to ask for summaries of your ChatBot session(s) and paste these into your homework notebook (including link(s) to chat log histories if you're using ChatGPT)!***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce11ef1",
   "metadata": {},
   "source": [
    "# Recommended Additional Useful Activities [Optional]\n",
    "\n",
    "The \"Ethical Profesionalism Considerations\" and \"Current Course Project Capability Level\" sections below **are not a part of the required homework assignment**; rather, they are regular weekly guides covering (a) relevant considerations regarding professional and ethical conduct, and (b) the analysis steps for the STA130 course project that are feasible at the current stage of the course<br><br>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Ethical Professionalism Considerations</u></summary>\n",
    "\n",
    "## Ethical Professionalism Considerations\n",
    "\n",
    "> If the observed data is \"no events occured\" does this mean the data is \"missing\" and [should be ignored](https://priceonomics.com/the-space-shuttle-challenger-explosion-and-the-o)?\n",
    "> \n",
    "> - NASA: \\<determines temperature doesn't affects \"o-ring\" by subseting data to just \"o-ring\" incidents\\>\n",
    "> - Also NASA: \\<launches the shuttle on a cold day\\>\n",
    "\n",
    "|No apparent \"o-ring\" failure and temperature relationship|Apparent between \"o-ring\" failure and temperature relationship|\n",
    "|:-|:-|\n",
    "if you just look at \"o-ring\" failure event data|if you instead look at ALL the data as you should|\n",
    "|![](https://etzq49yfnmd.exactdn.com/wp-content/uploads/2022/03/image06-14.png)|![](https://etzq49yfnmd.exactdn.com/wp-content/uploads/2022/03/image02-33.png)|\n",
    "|![](https://upload.wikimedia.org/wikipedia/commons/8/8b/Shuttle_Challenger_explosion.gif?20190203170223)|![](https://i.makeagif.com/media/10-04-2014/nT57xW.gif)|\n",
    "\n",
    "<br>\n",
    "    \n",
    "</details>    \n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Current Course Project Capability Level</u></summary>\n",
    "\n",
    "## Current Course Project Capability Level\n",
    "\n",
    "> The data we'll use for the STA130 course project is based on the [Canadian Social Connection Survey](https://casch.org/cscs). Please see the [data use agreement](https://static1.squarespace.com/static/60283c2e174c122f8ebe0f39/t/6239c284d610f76fed5a2e69/1647952517436/Data+Use+Agreement+for+the+Canadian+Social+Connection+Survey.pdf) regarding the appropriate and ethical professional use of this data (available at the bottom of the [CSCS](https://casch.org/cscs) webpage).\n",
    "> \n",
    "> 1. Have a very quick look at the list of available variables available using the [link](https://drive.google.com/file/d/1ISVymGn-WR1lcRs4psIym2N3or5onNBi/view) (again at the bottom of the [CSCS](https://casch.org/cscs) webpage); then, \n",
    "> 2. examine the code in the first thirteen code cells of [STA130F24_CourseProject.ipynb](https://github.com/pointOfive/stat130chat130/blob/main/CP/STA130F24_CourseProject.ipynb) to get an initital understanding of how we might subset to different studies included in the [data](https://drive.google.com/file/d/1mbUQlMTrNYA7Ly5eImVRBn16Ehy9Lggo/view) (again accessible at the bottom of the [CSCS](https://casch.org/cscs) webpage); then,     \n",
    "> 3. review the fourteenth and fifteenth cells (with the comments \"Here's a high level summary of the data\" and \"And here are some explanations about the columns in the data\") a little more closely to get a better sense of which columns seem to be the most interesting and whether or not they seem to have a lot of missing data\n",
    "    \n",
    "</details>        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ca7d22",
   "metadata": {},
   "source": [
    "### Afterward\n",
    "\n",
    "Here are few ideas of some other kinds of interactions you might consider exploring with a ChatBot...\n",
    "\n",
    "> While these are likely to be extremely practically valuable, they are not a part of the homework assignment, so do not include anything related to these in your homework submission\n",
    "\n",
    "- With respect to improving ones ability in statistics, coding, communication, and other key data science skills\n",
    "    - what is the ChatBots perception its own capabilities and uses as an AI-driven assistance tool \n",
    "    - and does ChatBots assessment of itself influence or agree with your own evalution of the ChatBot? \n",
    "\n",
    "- ChatBots can introduce and explain the \"World War 2 planes\" problem and the \"Monte Hall\" problem... \n",
    "    - how well does do they seem to do and introducing and explaining other \"unintuitive surprising statistics paradoxes\"?\n",
    "\n",
    "- If you consider the process of writing about why you chose to take this course, and the skills you were hoping to build through this course with respect to your current ideas about what possible careers \n",
    "    - and how do you think the exercise would be different if you framed it as a dialogue with a ChatBot\n",
    "    - and do you think the difference could be positive and productive, or potentially biasing and distracting?\n",
    "    \n",
    "- ChatBots sometimes immediately responds in simple helpful ways, but other times it gives a lot of extraneous information that can be overwheling... are you able to prompt and interact with ChatBots in manner that keeps its reponses helpful and focused on what you're interested in? \n",
    "\n",
    "- ChatBots tends to respond in a fairly empathetic and supportive tone...\n",
    "    - do you find it helpful to discuss concerns you might have about succeeding in the course (or entering university more generally) with a ChatBot?\n",
    "    \n",
    "- For what purposes and in what contexts do you think a ChatBot could provide suggestions or feedback about your experiences that might be useful? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f19898c",
   "metadata": {},
   "source": [
    "make some changes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49860cef",
   "metadata": {},
   "source": [
    "# 1. Using Animal Crossing data provided in the homework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d032941",
   "metadata": {},
   "source": [
    "# 2.1 print rows and columns in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c361c93",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 391\n",
      "Number of columns: 11\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "villagers_df = pd.read_csv(url)\n",
    "\n",
    "# Get the number of rows and columns\n",
    "num_rows, num_columns = villagers_df.shape\n",
    "print(f\"Number of rows: {num_rows}\")\n",
    "print(f\"Number of columns: {num_columns}\")\n",
    "# chatbot link https://chatgpt.com/share/25448bde-7e05-4df7-b85f-ed204be3eccf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d8759d",
   "metadata": {},
   "source": [
    "# 2.2 Observation & variable definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a08a106",
   "metadata": {},
   "source": [
    "# Observation: \n",
    "An observation is a row of the dataset, which represents a single record. An observation typically contains values for multiple attributes (or features/variables), which are the different pieces of information being collected.\n",
    "In the Animal Crossing dataset, an observation (row) represents a unique villager.\n",
    "\n",
    "# Variable: \n",
    "A variable is a column in the dataset, representing a different characteristic/attribute of the villagers like the id, species, personality, etc.\n",
    "\n",
    "\n",
    "# chatbot history + summary:\n",
    "ChatGPT's definitions (chat history:https://chatgpt.com/share/8b3cf3fe-a46e-42c4-be71-f25bf6bae09c, https://chatgpt.com/share/00f930f1-af6b-4774-a7ad-02c80c184bc1) \n",
    "Here's a summary of our interaction:\n",
    "\n",
    "1. You asked about what an **observation** is in the context of coding and datasets. I explained that an observation represents a single row in a dataset, with each row containing information about one data point (e.g., a villager in your Animal Crossing dataset).\n",
    "   \n",
    "2. You inquired about the definition of a **variable** in relation to your dataset. I clarified that a variable is a specific characteristic or attribute recorded for each observation (i.e., a column in your dataset), such as `name`, `species`, `personality`, etc.\n",
    "\n",
    "We also discussed examples of categorical variables and how they are structured in your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b75c22a",
   "metadata": {},
   "source": [
    "# 3. summary of columns using df.describe() & df['col'].value_counts()\n",
    "\n",
    "To get a summary of numeric columns, we should use villagers_df.describe(), which will provide us with the counts, mean, etc.\n",
    "To get a summary of both numeric and non-numeric (categorical) columns, we should use villagers_df.describe(include='all'), which will summarize the count, unique values, most frequent value (top), and its frequency (freq)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8de6635b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            row_n\n",
      "count  391.000000\n",
      "mean   239.902813\n",
      "std    140.702672\n",
      "min      2.000000\n",
      "25%    117.500000\n",
      "50%    240.000000\n",
      "75%    363.500000\n",
      "max    483.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "villagers_df = pd.read_csv(url)\n",
    "print(villagers_df.describe())\n",
    "# summary of numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "021f6845",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             row_n       id     name gender species birthday personality  \\\n",
      "count   391.000000      390      391    391     391      391         391   \n",
      "unique         NaN      390      391      2      35      361           8   \n",
      "top            NaN  admiral  Admiral   male     cat     1-27        lazy   \n",
      "freq           NaN        1        1    204      23        2          60   \n",
      "mean    239.902813      NaN      NaN    NaN     NaN      NaN         NaN   \n",
      "std     140.702672      NaN      NaN    NaN     NaN      NaN         NaN   \n",
      "min       2.000000      NaN      NaN    NaN     NaN      NaN         NaN   \n",
      "25%     117.500000      NaN      NaN    NaN     NaN      NaN         NaN   \n",
      "50%     240.000000      NaN      NaN    NaN     NaN      NaN         NaN   \n",
      "75%     363.500000      NaN      NaN    NaN     NaN      NaN         NaN   \n",
      "max     483.000000      NaN      NaN    NaN     NaN      NaN         NaN   \n",
      "\n",
      "                song   phrase           full_id  \\\n",
      "count            380      391               391   \n",
      "unique            92      388               391   \n",
      "top     K.K. Country  wee one  villager-admiral   \n",
      "freq              10        2                 1   \n",
      "mean             NaN      NaN               NaN   \n",
      "std              NaN      NaN               NaN   \n",
      "min              NaN      NaN               NaN   \n",
      "25%              NaN      NaN               NaN   \n",
      "50%              NaN      NaN               NaN   \n",
      "75%              NaN      NaN               NaN   \n",
      "max              NaN      NaN               NaN   \n",
      "\n",
      "                                                      url  \n",
      "count                                                 391  \n",
      "unique                                                391  \n",
      "top     https://villagerdb.com/images/villagers/thumb/...  \n",
      "freq                                                    1  \n",
      "mean                                                  NaN  \n",
      "std                                                   NaN  \n",
      "min                                                   NaN  \n",
      "25%                                                   NaN  \n",
      "50%                                                   NaN  \n",
      "75%                                                   NaN  \n",
      "max                                                   NaN  \n"
     ]
    }
   ],
   "source": [
    "print(villagers_df.describe(include='all'))\n",
    "# summary of ALL columns, including categorical ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9faf9ca",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['row_n', 'id', 'name', 'gender', 'species', 'birthday', 'personality',\n",
      "       'song', 'phrase', 'full_id', 'url'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(villagers_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23dc282c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row_n\n",
      "2      1\n",
      "303    1\n",
      "331    1\n",
      "330    1\n",
      "328    1\n",
      "      ..\n",
      "151    1\n",
      "150    1\n",
      "149    1\n",
      "148    1\n",
      "483    1\n",
      "Name: count, Length: 391, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(villagers_df['row_n'].value_counts()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a303696",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "admiral    1\n",
      "mott       1\n",
      "paula      1\n",
      "patty      1\n",
      "pate       1\n",
      "          ..\n",
      "eloise     1\n",
      "elmer      1\n",
      "ellie      1\n",
      "elise      1\n",
      "zucker     1\n",
      "Name: count, Length: 390, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "villagers_df = pd.read_csv(url)\n",
    "print(villagers_df['id'].value_counts()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf965319",
   "metadata": {},
   "source": [
    "# chatbot history + summary\n",
    "chatbot history: https://chatgpt.com/share/8b3cf3fe-a46e-42c4-be71-f25bf6bae09c\n",
    "couldn't get a summary for this chat because I went over the amount of questions you're allowed to ask. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa655653",
   "metadata": {},
   "source": [
    "# 4. Explain discrepancies: compare df.shapes vs df.describe() using titanic dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccec444",
   "metadata": {},
   "source": [
    "# df.shape:\n",
    "df.shape is an attribute (is a piece of data as opposed to performing an action and returning a result) containing the dimensions of the dataframe as (number of rows, number of columns). It is used to quickly understand the size of our dataframe.\n",
    "\n",
    "df.shape just contains the dimensions of the dataset.\n",
    "\n",
    "In the output of the cell below, the shape of the titanic dataset is (891, 15) which means that there are 891 rows and 15 columns of data in our table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "147858fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset: (891, 15)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "t_url= \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "t_df = pd.read_csv(t_url)\n",
    "print(\"Shape of the dataset:\", t_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8e9753",
   "metadata": {},
   "source": [
    "# df.describe():\n",
    "df.describe() is a method (a function) which provides summary statistics of the dataframe's numerical columns by returning the count, mean, standard deviation, minimum, quartiles (25%, 50%, 75%), and maximum for each numerical column. It is used to quickly get a central tendency, dispersion, and shape of the numerical columns in a dataset.\n",
    "\n",
    "By default, df.describe() returns numerical columns only. To return the counts and frequency statistics of non-numeric columns as well, we should use df.describe(include='all'). \n",
    "\n",
    "The statistics in df.describe() only reflect non-missing values. As a result, the count for some columns may be lower than the number of rows (from df.shape) if there are missing values. \n",
    "For example, in the 'age' column, 714 is displayed as the count, which represents how many people's ages are known of 891 rows total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08338fea",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          survived      pclass   sex         age       sibsp       parch  \\\n",
      "count   891.000000  891.000000   891  714.000000  891.000000  891.000000   \n",
      "unique         NaN         NaN     2         NaN         NaN         NaN   \n",
      "top            NaN         NaN  male         NaN         NaN         NaN   \n",
      "freq           NaN         NaN   577         NaN         NaN         NaN   \n",
      "mean      0.383838    2.308642   NaN   29.699118    0.523008    0.381594   \n",
      "std       0.486592    0.836071   NaN   14.526497    1.102743    0.806057   \n",
      "min       0.000000    1.000000   NaN    0.420000    0.000000    0.000000   \n",
      "25%       0.000000    2.000000   NaN   20.125000    0.000000    0.000000   \n",
      "50%       0.000000    3.000000   NaN   28.000000    0.000000    0.000000   \n",
      "75%       1.000000    3.000000   NaN   38.000000    1.000000    0.000000   \n",
      "max       1.000000    3.000000   NaN   80.000000    8.000000    6.000000   \n",
      "\n",
      "              fare embarked  class  who adult_male deck  embark_town alive  \\\n",
      "count   891.000000      889    891  891        891  203          889   891   \n",
      "unique         NaN        3      3    3          2    7            3     2   \n",
      "top            NaN        S  Third  man       True    C  Southampton    no   \n",
      "freq           NaN      644    491  537        537   59          644   549   \n",
      "mean     32.204208      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "std      49.693429      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "min       0.000000      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "25%       7.910400      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "50%      14.454200      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "75%      31.000000      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "max     512.329200      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "\n",
      "       alone  \n",
      "count    891  \n",
      "unique     2  \n",
      "top     True  \n",
      "freq     537  \n",
      "mean     NaN  \n",
      "std      NaN  \n",
      "min      NaN  \n",
      "25%      NaN  \n",
      "50%      NaN  \n",
      "75%      NaN  \n",
      "max      NaN  \n"
     ]
    }
   ],
   "source": [
    "print(t_df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf89112d",
   "metadata": {},
   "source": [
    "# chatbot history + summary for question 4\n",
    "https://chatgpt.com/share/f86b4698-8ac6-476c-97fe-9c05bd010e39\n",
    "Here's a summary of our interaction:\n",
    "\n",
    "1. **Question on `df.shape` and `df.describe()`**:\n",
    "   - You asked about the difference between `df.shape` and `df.describe()`.\n",
    "   - I explained that `df.shape` returns the dimensions of the DataFrame (as a tuple: number of rows, number of columns), while `df.describe()` provides summary statistics for the numerical columns of the DataFrame.\n",
    "\n",
    "2. **Attributes vs Methods**:\n",
    "   - You asked how these relate to attributes and methods.\n",
    "   - I explained that:\n",
    "     - **`df.shape` is an attribute** because it represents a property of the DataFrame and does not require parentheses.\n",
    "     - **`df.describe()` is a method** because it performs a calculation and needs to be called with parentheses.\n",
    "\n",
    "Let me know if you'd like more information or have any further questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cd77a5",
   "metadata": {},
   "source": [
    "# 5. difference between attributes and methods "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758002b9",
   "metadata": {},
   "source": [
    "# Methods:\n",
    "A method is a function that belongs to an object and performs an action,  computations, transformations, or other actions on the data. Methods require parentheses () to be performed.\n",
    "\n",
    "df.describe() is an example of a method as it performs an operation on the DataFrame to calculate the summary statistics for the numerical columns, outputting the counts, mean, std, min, max, 25%, 50%, and 75% percentile. \n",
    "Since it’s a function, you need parentheses. \n",
    "\n",
    "# Attributes:\n",
    "An attribute is a value associated with an object that can be referred to by a specific name. It is a piece of data that you should access it without using parentheses. \n",
    "\n",
    "df.shape is an example of an attribute. It represents the dimensions (number of rows, number of columns) of a dataframe. In terms of the Animal Crossing dataframe, df.shape outputs (891, 15), meaning the dataframe has 891 rows and 15 columns of data.\n",
    "\n",
    "\n",
    "# function definition - programming vs mathematics:\n",
    "# mathematics defintion:\n",
    "A mathematical function is a relationship between a set of inputs and a set of possible outputs. Where each input gives exactly one output.\n",
    "\n",
    "# programming definition:\n",
    "A function (or method in python) in programming is a block of reusable code designed to perform a specific task. Taking inputs (called arguments or parameters) and returning a result or perform an action. In the case of df.describe(), the function (method) summarizes a the dataframes numerical data.\n",
    "\n",
    "# chatbot history + summary:\n",
    "https://chatgpt.com/share/f86b4698-8ac6-476c-97fe-9c05bd010e39\n",
    "Here's a summary of our interaction:\n",
    "\n",
    "1. **Question on `df.shape` and `df.describe()`**:\n",
    "   - You asked about the difference between `df.shape` and `df.describe()`.\n",
    "   - I explained that `df.shape` returns the dimensions of the DataFrame (as a tuple: number of rows, number of columns), while `df.describe()` provides summary statistics for the numerical columns of the DataFrame.\n",
    "\n",
    "2. **Attributes vs Methods**:\n",
    "   - You asked how these relate to attributes and methods.\n",
    "   - I explained that:\n",
    "     - **`df.shape` is an attribute** because it represents a property of the DataFrame and does not require parentheses.\n",
    "     - **`df.describe()` is a method** because it performs a calculation and needs to be called with parentheses.\n",
    "\n",
    "Let me know if you'd like more information or have any further questions!\n",
    "\n",
    "https://chatgpt.com/share/aa9404ae-0bc8-4018-a766-97f5ff0d94e6 --> function in programming vs mathematics\n",
    "Here’s a summary of our interaction:\n",
    "\n",
    "You asked about the difference between a function in programming and a function in mathematics. I explained that:\n",
    "\n",
    "- **Mathematical functions** define a relationship between inputs and outputs, where each input has a single output. They are deterministic, have no side effects, and are analyzed in terms of their abstract properties.\n",
    "  \n",
    "- **Programming functions** are reusable blocks of code that can perform tasks, return results, and sometimes cause side effects. They can be either deterministic or non-deterministic, handle complex logic, and interact with external states (e.g., files, variables).\n",
    "\n",
    "I also highlighted the key differences in terms of purpose, behavior, and flexibility.\n",
    "Let me know if you'd like more information or have any further questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb68b0ea",
   "metadata": {},
   "source": [
    "# 6 definition of summary statistics\n",
    "\n",
    "summary statistics are displayed when we call df.describe().\n",
    "as mentioned above, by default, df.describe() returns numerical columns only. To return the counts and frequency statistics of non-numeric columns as well, we should use df.describe(include='all'). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce13ca8",
   "metadata": {},
   "source": [
    "# using age as an example for each! \n",
    "\n",
    "# Count: \n",
    "The number of non-null observations in the dataset for each column. It shows how many valid non-null observations (rows) of data points are present.\n",
    "\n",
    "For example, 150 indicates 150 valid age entries.\n",
    "\n",
    "# Mean: \n",
    "The average value of the data in the column based solely on the available data that has valid numerical values. Any NaN (Not a Number) or null values are automatically excluded from the calculation of the mean.\n",
    "\n",
    "It is calculated by summing all the non-null (non-missing) values in a dataset and then dividing by the number of those values. \n",
    "\n",
    "For example, the average age of villagers.\n",
    "\n",
    "# Standard Deviation (std):\n",
    "A measure of the amount of variation or dispersion in a set of values (dataset). It indicates how spread out the values are around the mean. \n",
    "\n",
    "A high standard deviation means the values are more spread out from the mean, while a low standard deviation means they are closer to the mean. \n",
    "\n",
    "For example, 10.2 indicates a deviation in age by 10.2 years from the mean.\n",
    "\n",
    "# Minimum (min): \n",
    "The smallest value in the dataset in each column.\n",
    "For example, 18 represents the youngest age recorded.\n",
    "\n",
    "# Maximum (max): \n",
    "The largest value in the dataset in each column.\n",
    "For example, 65 represents the oldest age recorded.\n",
    "\n",
    "# 25th Percentile (25%): \n",
    "Also known as the first quartile, it represents the value below which 25% of the data falls. It’s the point at which 25% of the data is strictly less than this value and 75% is greater.\n",
    "For example, 25 means that 25% of the ages are younger than 25 years.\n",
    "\n",
    "# 50th Percentile (50%): \n",
    "Also known as the median, it’s the middle value of the dataset. Half of the data falls below this value, and half falls above it.\n",
    "For example, 34 means half of the ages of villagers are 34 years or younger and half are older.\n",
    "\n",
    "# 75th Percentile (75%): \n",
    "\n",
    "Also known as the third quartile, it represents the value below which 75% of the data falls. It’s the point at which 75% of the data is strictly less than this value and 25% is greater.\n",
    "For example, 45 means that 75% of the ages are younger than 45 years.\n",
    "\n",
    "# chatbot history + summary\n",
    "https://chatgpt.com/share/39e3ea29-0001-4088-9408-de4cd9ef4610\n",
    "Here’s a summary of our interaction:\n",
    "\n",
    "1. **Definitions of Summary Statistics**: I provided explanations for the summary statistics (`count`, `mean`, `std`, `min`, `25%`, `50%`, `75%`, and `max`) generated by the `df.describe()` method in pandas.\n",
    "   \n",
    "2. **Explanation of Use Case**: I explained what a use case is, including its key components (actor, scenario, goal, preconditions, postconditions, and exceptions) and gave an example of a use case for \"User Login.\"\n",
    "\n",
    "3. **Mean Calculation**: I explained that the mean is calculated by summing all non-null values in a dataset and dividing by the number of those values, and that `NaN` values are excluded from this calculation.\n",
    "\n",
    "If there's anything else you'd like to know or clarify, just let me know!\n",
    "Let me know if you'd like to dive deeper into any of these topics!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dd815c",
   "metadata": {},
   "source": [
    "# 7.  when to use df.dropna() vs del df['col']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117129d3",
   "metadata": {},
   "source": [
    "# df.dropna()\n",
    "a function that removes a single value in a row with any missing values. \n",
    "df.dropna() is used when dealing with rows or columns that contain missing values and you want to clean your dataset by removing incomplete data based on how many missing values you have. This helps ensure that your analysis is based on complete (non-missing) data points. \n",
    "\n",
    "# del df['col'] \n",
    "deletes an entire column based on an extreme amount of missing values. \n",
    "del df['col'] is used when you want to remove specific columns that you have deemed unnecessary for your analysis. This is not about cleaning missing values but about simplifying the structure of your dataset.\n",
    "\n",
    "In the context of the Animal Crossing dataset, the decision to use df.dropna() versus del df['col'] depends on what you're trying to accomplish with the data, especially in terms of handling missing values and column deletion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaab555",
   "metadata": {},
   "source": [
    "# 7.1 use case for when df.dropna() is preferred over del df['col']\n",
    "df.dropna() is used when we're interested in cleaning data by eliminating rows or columns based on the presence of missing values.\n",
    "\n",
    "df.dropna() is commonly used to clean data, prepare it for machine learning algorithms (which require a complete dataset, meaning no missing/null values), to simplify analysis, and to ensure consistency with data collection. \n",
    "\n",
    "For example, if we want to clean our data by dropping rows where any villager's details (such as species, personality, or birthday) have missing values (NaNs), we'd use df.dropna()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff0f86a1",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_n</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>species</th>\n",
       "      <th>birthday</th>\n",
       "      <th>personality</th>\n",
       "      <th>song</th>\n",
       "      <th>phrase</th>\n",
       "      <th>full_id</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>admiral</td>\n",
       "      <td>Admiral</td>\n",
       "      <td>male</td>\n",
       "      <td>bird</td>\n",
       "      <td>1-27</td>\n",
       "      <td>cranky</td>\n",
       "      <td>Steep Hill</td>\n",
       "      <td>aye aye</td>\n",
       "      <td>villager-admiral</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>agent-s</td>\n",
       "      <td>Agent S</td>\n",
       "      <td>female</td>\n",
       "      <td>squirrel</td>\n",
       "      <td>7-2</td>\n",
       "      <td>peppy</td>\n",
       "      <td>DJ K.K.</td>\n",
       "      <td>sidekick</td>\n",
       "      <td>villager-agent-s</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>agnes</td>\n",
       "      <td>Agnes</td>\n",
       "      <td>female</td>\n",
       "      <td>pig</td>\n",
       "      <td>4-21</td>\n",
       "      <td>uchi</td>\n",
       "      <td>K.K. House</td>\n",
       "      <td>snuffle</td>\n",
       "      <td>villager-agnes</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>al</td>\n",
       "      <td>Al</td>\n",
       "      <td>male</td>\n",
       "      <td>gorilla</td>\n",
       "      <td>10-18</td>\n",
       "      <td>lazy</td>\n",
       "      <td>Steep Hill</td>\n",
       "      <td>Ayyeeee</td>\n",
       "      <td>villager-al</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>alfonso</td>\n",
       "      <td>Alfonso</td>\n",
       "      <td>male</td>\n",
       "      <td>alligator</td>\n",
       "      <td>6-9</td>\n",
       "      <td>lazy</td>\n",
       "      <td>Forest Life</td>\n",
       "      <td>it'sa me</td>\n",
       "      <td>villager-alfonso</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>475</td>\n",
       "      <td>winnie</td>\n",
       "      <td>Winnie</td>\n",
       "      <td>female</td>\n",
       "      <td>horse</td>\n",
       "      <td>1-31</td>\n",
       "      <td>peppy</td>\n",
       "      <td>My Place</td>\n",
       "      <td>hay-OK</td>\n",
       "      <td>villager-winnie</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>477</td>\n",
       "      <td>wolfgang</td>\n",
       "      <td>Wolfgang</td>\n",
       "      <td>male</td>\n",
       "      <td>wolf</td>\n",
       "      <td>11-25</td>\n",
       "      <td>cranky</td>\n",
       "      <td>K.K. Song</td>\n",
       "      <td>snarrrl</td>\n",
       "      <td>villager-wolfgang</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>480</td>\n",
       "      <td>yuka</td>\n",
       "      <td>Yuka</td>\n",
       "      <td>female</td>\n",
       "      <td>koala</td>\n",
       "      <td>7-20</td>\n",
       "      <td>snooty</td>\n",
       "      <td>Soulful K.K.</td>\n",
       "      <td>tsk tsk</td>\n",
       "      <td>villager-yuka</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>481</td>\n",
       "      <td>zell</td>\n",
       "      <td>Zell</td>\n",
       "      <td>male</td>\n",
       "      <td>deer</td>\n",
       "      <td>6-7</td>\n",
       "      <td>smug</td>\n",
       "      <td>K.K. D&amp;B</td>\n",
       "      <td>pronk</td>\n",
       "      <td>villager-zell</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>483</td>\n",
       "      <td>zucker</td>\n",
       "      <td>Zucker</td>\n",
       "      <td>male</td>\n",
       "      <td>octopus</td>\n",
       "      <td>3-8</td>\n",
       "      <td>lazy</td>\n",
       "      <td>Spring Blossoms</td>\n",
       "      <td>bloop</td>\n",
       "      <td>villager-zucker</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>379 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     row_n        id      name  gender    species birthday personality  \\\n",
       "0        2   admiral   Admiral    male       bird     1-27      cranky   \n",
       "1        3   agent-s   Agent S  female   squirrel      7-2       peppy   \n",
       "2        4     agnes     Agnes  female        pig     4-21        uchi   \n",
       "3        6        al        Al    male    gorilla    10-18        lazy   \n",
       "4        7   alfonso   Alfonso    male  alligator      6-9        lazy   \n",
       "..     ...       ...       ...     ...        ...      ...         ...   \n",
       "386    475    winnie    Winnie  female      horse     1-31       peppy   \n",
       "387    477  wolfgang  Wolfgang    male       wolf    11-25      cranky   \n",
       "388    480      yuka      Yuka  female      koala     7-20      snooty   \n",
       "389    481      zell      Zell    male       deer      6-7        smug   \n",
       "390    483    zucker    Zucker    male    octopus      3-8        lazy   \n",
       "\n",
       "                song    phrase            full_id  \\\n",
       "0         Steep Hill   aye aye   villager-admiral   \n",
       "1            DJ K.K.  sidekick   villager-agent-s   \n",
       "2         K.K. House   snuffle     villager-agnes   \n",
       "3         Steep Hill   Ayyeeee        villager-al   \n",
       "4        Forest Life  it'sa me   villager-alfonso   \n",
       "..               ...       ...                ...   \n",
       "386         My Place    hay-OK    villager-winnie   \n",
       "387        K.K. Song   snarrrl  villager-wolfgang   \n",
       "388     Soulful K.K.   tsk tsk      villager-yuka   \n",
       "389         K.K. D&B     pronk      villager-zell   \n",
       "390  Spring Blossoms     bloop    villager-zucker   \n",
       "\n",
       "                                                   url  \n",
       "0    https://villagerdb.com/images/villagers/thumb/...  \n",
       "1    https://villagerdb.com/images/villagers/thumb/...  \n",
       "2    https://villagerdb.com/images/villagers/thumb/...  \n",
       "3    https://villagerdb.com/images/villagers/thumb/...  \n",
       "4    https://villagerdb.com/images/villagers/thumb/...  \n",
       "..                                                 ...  \n",
       "386  https://villagerdb.com/images/villagers/thumb/...  \n",
       "387  https://villagerdb.com/images/villagers/thumb/...  \n",
       "388  https://villagerdb.com/images/villagers/thumb/...  \n",
       "389  https://villagerdb.com/images/villagers/thumb/...  \n",
       "390  https://villagerdb.com/images/villagers/thumb/...  \n",
       "\n",
       "[379 rows x 11 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of using df.dropna() with Animal Crossing dataset\n",
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "villagers_df = pd.read_csv(url)\n",
    "# Drop rows with missing values in any column\n",
    "villagers_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde1c064",
   "metadata": {},
   "source": [
    "When a column is essential for your analysis (like species or personality) and missing data would skew your results, use dropna(subset=[columns]).\n",
    "See cell below for an example of cleaning rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23f40d0a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_n</th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>species</th>\n",
       "      <th>birthday</th>\n",
       "      <th>personality</th>\n",
       "      <th>song</th>\n",
       "      <th>phrase</th>\n",
       "      <th>full_id</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Admiral</td>\n",
       "      <td>male</td>\n",
       "      <td>bird</td>\n",
       "      <td>1-27</td>\n",
       "      <td>cranky</td>\n",
       "      <td>Steep Hill</td>\n",
       "      <td>aye aye</td>\n",
       "      <td>villager-admiral</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Agent S</td>\n",
       "      <td>female</td>\n",
       "      <td>squirrel</td>\n",
       "      <td>7-2</td>\n",
       "      <td>peppy</td>\n",
       "      <td>DJ K.K.</td>\n",
       "      <td>sidekick</td>\n",
       "      <td>villager-agent-s</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Agnes</td>\n",
       "      <td>female</td>\n",
       "      <td>pig</td>\n",
       "      <td>4-21</td>\n",
       "      <td>uchi</td>\n",
       "      <td>K.K. House</td>\n",
       "      <td>snuffle</td>\n",
       "      <td>villager-agnes</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>Al</td>\n",
       "      <td>male</td>\n",
       "      <td>gorilla</td>\n",
       "      <td>10-18</td>\n",
       "      <td>lazy</td>\n",
       "      <td>Steep Hill</td>\n",
       "      <td>Ayyeeee</td>\n",
       "      <td>villager-al</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>Alfonso</td>\n",
       "      <td>male</td>\n",
       "      <td>alligator</td>\n",
       "      <td>6-9</td>\n",
       "      <td>lazy</td>\n",
       "      <td>Forest Life</td>\n",
       "      <td>it'sa me</td>\n",
       "      <td>villager-alfonso</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>475</td>\n",
       "      <td>Winnie</td>\n",
       "      <td>female</td>\n",
       "      <td>horse</td>\n",
       "      <td>1-31</td>\n",
       "      <td>peppy</td>\n",
       "      <td>My Place</td>\n",
       "      <td>hay-OK</td>\n",
       "      <td>villager-winnie</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>477</td>\n",
       "      <td>Wolfgang</td>\n",
       "      <td>male</td>\n",
       "      <td>wolf</td>\n",
       "      <td>11-25</td>\n",
       "      <td>cranky</td>\n",
       "      <td>K.K. Song</td>\n",
       "      <td>snarrrl</td>\n",
       "      <td>villager-wolfgang</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>480</td>\n",
       "      <td>Yuka</td>\n",
       "      <td>female</td>\n",
       "      <td>koala</td>\n",
       "      <td>7-20</td>\n",
       "      <td>snooty</td>\n",
       "      <td>Soulful K.K.</td>\n",
       "      <td>tsk tsk</td>\n",
       "      <td>villager-yuka</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>481</td>\n",
       "      <td>Zell</td>\n",
       "      <td>male</td>\n",
       "      <td>deer</td>\n",
       "      <td>6-7</td>\n",
       "      <td>smug</td>\n",
       "      <td>K.K. D&amp;B</td>\n",
       "      <td>pronk</td>\n",
       "      <td>villager-zell</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>483</td>\n",
       "      <td>Zucker</td>\n",
       "      <td>male</td>\n",
       "      <td>octopus</td>\n",
       "      <td>3-8</td>\n",
       "      <td>lazy</td>\n",
       "      <td>Spring Blossoms</td>\n",
       "      <td>bloop</td>\n",
       "      <td>villager-zucker</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>391 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     row_n      name  gender    species birthday personality             song  \\\n",
       "0        2   Admiral    male       bird     1-27      cranky       Steep Hill   \n",
       "1        3   Agent S  female   squirrel      7-2       peppy          DJ K.K.   \n",
       "2        4     Agnes  female        pig     4-21        uchi       K.K. House   \n",
       "3        6        Al    male    gorilla    10-18        lazy       Steep Hill   \n",
       "4        7   Alfonso    male  alligator      6-9        lazy      Forest Life   \n",
       "..     ...       ...     ...        ...      ...         ...              ...   \n",
       "386    475    Winnie  female      horse     1-31       peppy         My Place   \n",
       "387    477  Wolfgang    male       wolf    11-25      cranky        K.K. Song   \n",
       "388    480      Yuka  female      koala     7-20      snooty     Soulful K.K.   \n",
       "389    481      Zell    male       deer      6-7        smug         K.K. D&B   \n",
       "390    483    Zucker    male    octopus      3-8        lazy  Spring Blossoms   \n",
       "\n",
       "       phrase            full_id  \\\n",
       "0     aye aye   villager-admiral   \n",
       "1    sidekick   villager-agent-s   \n",
       "2     snuffle     villager-agnes   \n",
       "3     Ayyeeee        villager-al   \n",
       "4    it'sa me   villager-alfonso   \n",
       "..        ...                ...   \n",
       "386    hay-OK    villager-winnie   \n",
       "387   snarrrl  villager-wolfgang   \n",
       "388   tsk tsk      villager-yuka   \n",
       "389     pronk      villager-zell   \n",
       "390     bloop    villager-zucker   \n",
       "\n",
       "                                                   url  \n",
       "0    https://villagerdb.com/images/villagers/thumb/...  \n",
       "1    https://villagerdb.com/images/villagers/thumb/...  \n",
       "2    https://villagerdb.com/images/villagers/thumb/...  \n",
       "3    https://villagerdb.com/images/villagers/thumb/...  \n",
       "4    https://villagerdb.com/images/villagers/thumb/...  \n",
       "..                                                 ...  \n",
       "386  https://villagerdb.com/images/villagers/thumb/...  \n",
       "387  https://villagerdb.com/images/villagers/thumb/...  \n",
       "388  https://villagerdb.com/images/villagers/thumb/...  \n",
       "389  https://villagerdb.com/images/villagers/thumb/...  \n",
       "390  https://villagerdb.com/images/villagers/thumb/...  \n",
       "\n",
       "[391 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cleaning rows with missing values for specific analysis which requires a complete data (no missing values)\n",
    "# use df.dropna() to drop rows that contains missing values as it might cause issues\n",
    "villagers_df.dropna(subset=['species', 'personality', 'birthday'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0044315",
   "metadata": {},
   "source": [
    "For analyzing complete subsets of the data, such as song-based analysis, use dropna() on relevant columns to ensure no rows with critical missing data distort your results by emoving the columns with excessive missing data that aren't contributing to your analysis.\n",
    "\n",
    "see cell below for an example of removing rows   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "316b0e8d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_n</th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>species</th>\n",
       "      <th>birthday</th>\n",
       "      <th>personality</th>\n",
       "      <th>song</th>\n",
       "      <th>phrase</th>\n",
       "      <th>full_id</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Admiral</td>\n",
       "      <td>male</td>\n",
       "      <td>bird</td>\n",
       "      <td>1-27</td>\n",
       "      <td>cranky</td>\n",
       "      <td>Steep Hill</td>\n",
       "      <td>aye aye</td>\n",
       "      <td>villager-admiral</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Agent S</td>\n",
       "      <td>female</td>\n",
       "      <td>squirrel</td>\n",
       "      <td>7-2</td>\n",
       "      <td>peppy</td>\n",
       "      <td>DJ K.K.</td>\n",
       "      <td>sidekick</td>\n",
       "      <td>villager-agent-s</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Agnes</td>\n",
       "      <td>female</td>\n",
       "      <td>pig</td>\n",
       "      <td>4-21</td>\n",
       "      <td>uchi</td>\n",
       "      <td>K.K. House</td>\n",
       "      <td>snuffle</td>\n",
       "      <td>villager-agnes</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>Al</td>\n",
       "      <td>male</td>\n",
       "      <td>gorilla</td>\n",
       "      <td>10-18</td>\n",
       "      <td>lazy</td>\n",
       "      <td>Steep Hill</td>\n",
       "      <td>Ayyeeee</td>\n",
       "      <td>villager-al</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>Alfonso</td>\n",
       "      <td>male</td>\n",
       "      <td>alligator</td>\n",
       "      <td>6-9</td>\n",
       "      <td>lazy</td>\n",
       "      <td>Forest Life</td>\n",
       "      <td>it'sa me</td>\n",
       "      <td>villager-alfonso</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>475</td>\n",
       "      <td>Winnie</td>\n",
       "      <td>female</td>\n",
       "      <td>horse</td>\n",
       "      <td>1-31</td>\n",
       "      <td>peppy</td>\n",
       "      <td>My Place</td>\n",
       "      <td>hay-OK</td>\n",
       "      <td>villager-winnie</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>477</td>\n",
       "      <td>Wolfgang</td>\n",
       "      <td>male</td>\n",
       "      <td>wolf</td>\n",
       "      <td>11-25</td>\n",
       "      <td>cranky</td>\n",
       "      <td>K.K. Song</td>\n",
       "      <td>snarrrl</td>\n",
       "      <td>villager-wolfgang</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>480</td>\n",
       "      <td>Yuka</td>\n",
       "      <td>female</td>\n",
       "      <td>koala</td>\n",
       "      <td>7-20</td>\n",
       "      <td>snooty</td>\n",
       "      <td>Soulful K.K.</td>\n",
       "      <td>tsk tsk</td>\n",
       "      <td>villager-yuka</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>481</td>\n",
       "      <td>Zell</td>\n",
       "      <td>male</td>\n",
       "      <td>deer</td>\n",
       "      <td>6-7</td>\n",
       "      <td>smug</td>\n",
       "      <td>K.K. D&amp;B</td>\n",
       "      <td>pronk</td>\n",
       "      <td>villager-zell</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>483</td>\n",
       "      <td>Zucker</td>\n",
       "      <td>male</td>\n",
       "      <td>octopus</td>\n",
       "      <td>3-8</td>\n",
       "      <td>lazy</td>\n",
       "      <td>Spring Blossoms</td>\n",
       "      <td>bloop</td>\n",
       "      <td>villager-zucker</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>380 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     row_n      name  gender    species birthday personality             song  \\\n",
       "0        2   Admiral    male       bird     1-27      cranky       Steep Hill   \n",
       "1        3   Agent S  female   squirrel      7-2       peppy          DJ K.K.   \n",
       "2        4     Agnes  female        pig     4-21        uchi       K.K. House   \n",
       "3        6        Al    male    gorilla    10-18        lazy       Steep Hill   \n",
       "4        7   Alfonso    male  alligator      6-9        lazy      Forest Life   \n",
       "..     ...       ...     ...        ...      ...         ...              ...   \n",
       "386    475    Winnie  female      horse     1-31       peppy         My Place   \n",
       "387    477  Wolfgang    male       wolf    11-25      cranky        K.K. Song   \n",
       "388    480      Yuka  female      koala     7-20      snooty     Soulful K.K.   \n",
       "389    481      Zell    male       deer      6-7        smug         K.K. D&B   \n",
       "390    483    Zucker    male    octopus      3-8        lazy  Spring Blossoms   \n",
       "\n",
       "       phrase            full_id  \\\n",
       "0     aye aye   villager-admiral   \n",
       "1    sidekick   villager-agent-s   \n",
       "2     snuffle     villager-agnes   \n",
       "3     Ayyeeee        villager-al   \n",
       "4    it'sa me   villager-alfonso   \n",
       "..        ...                ...   \n",
       "386    hay-OK    villager-winnie   \n",
       "387   snarrrl  villager-wolfgang   \n",
       "388   tsk tsk      villager-yuka   \n",
       "389     pronk      villager-zell   \n",
       "390     bloop    villager-zucker   \n",
       "\n",
       "                                                   url  \n",
       "0    https://villagerdb.com/images/villagers/thumb/...  \n",
       "1    https://villagerdb.com/images/villagers/thumb/...  \n",
       "2    https://villagerdb.com/images/villagers/thumb/...  \n",
       "3    https://villagerdb.com/images/villagers/thumb/...  \n",
       "4    https://villagerdb.com/images/villagers/thumb/...  \n",
       "..                                                 ...  \n",
       "386  https://villagerdb.com/images/villagers/thumb/...  \n",
       "387  https://villagerdb.com/images/villagers/thumb/...  \n",
       "388  https://villagerdb.com/images/villagers/thumb/...  \n",
       "389  https://villagerdb.com/images/villagers/thumb/...  \n",
       "390  https://villagerdb.com/images/villagers/thumb/...  \n",
       "\n",
       "[380 rows x 10 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing rows with missing data (i.e. 'song')\n",
    "# use df.dropna() to drop missing values in 'song' column that could make results incomplete \n",
    "villagers_df.dropna(subset=['song'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b168a509",
   "metadata": {},
   "source": [
    "# 7.2 use case for when del df['col'] is preferred over df.dropna()\n",
    "del df['col'] is used when you know exactly which column you want to remove from the DataFrame, regardless of whether it contains missing values. This is helpful when aspecific column is irrelevant to your analysis, and you want to remove it for clarity and focus. \n",
    "\n",
    "For example, if the 'id' column isn't relevant in my analysis of 'birthday' and 'songs', then I can delete that column using del df['col'] to simplify the data I use for my analysis. \n",
    "An example of deleting the 'id' column is shown in the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7635ad96",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['row_n', 'id', 'name', 'gender', 'species', 'birthday', 'personality',\n",
       "       'song', 'phrase', 'full_id', 'url'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# before deleting a column (using 'id' as the example)\n",
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "villagers_df = pd.read_csv(url)\n",
    "villagers_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "028b8816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting the 'id' column\n",
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "villagers_df = pd.read_csv(url)\n",
    "del villagers_df['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6f37b11",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after deletion: Index(['row_n', 'name', 'gender', 'species', 'birthday', 'personality', 'song',\n",
      "       'phrase', 'full_id', 'url'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Display columns after deletion\n",
    "print(\"Columns after deletion:\", villagers_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db51366",
   "metadata": {},
   "source": [
    "# 7.3 applying del df['col'] before df.dropna() is important"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178671b8",
   "metadata": {},
   "source": [
    "When using df.dropna() and deleting a column with del df['col'], the order matters. If you delete the column first del df['col'], you ensure that you don't unintentionally remove important rows due to NaN values in that column. Then, when you apply df.dropna(), it only affects the remaining columns. \n",
    "\n",
    "If you use df.dropna() before deleting the column, it will remove rows with NaN values in any column, including the one you might want to delete later. Thus, you might end up dropping rows you could have kept if you deleted the column first.\n",
    "\n",
    "Deleting unnecessary columns before applying df.dropna() can help maintain data integrity and improve performance by reducing the amount of data to process in subsequent steps.\n",
    "\n",
    "# chatbot history + summary\n",
    "https://chatgpt.com/share/6f6f246f-3654-4628-99aa-0747122d0dc7\n",
    "You asked about the importance of applying `del df['col']` before `df.dropna()` when both are used together. I explained that deleting the column first ensures you don’t inadvertently drop rows that might have been important if they had NaN values only in the column you plan to remove. This approach helps maintain data integrity and can improve performance by reducing computational overhead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b46dc4b",
   "metadata": {},
   "source": [
    "# 7.4 how to efficiently remove missing data using del df['col'] df.dropna() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bef935be",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row_n           0\n",
      "id              1\n",
      "name            0\n",
      "gender          0\n",
      "species         0\n",
      "birthday        0\n",
      "personality     0\n",
      "song           11\n",
      "phrase          0\n",
      "full_id         0\n",
      "url             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# see how many missing values in the animal crossing dataset\n",
    "import pandas as pd\n",
    "url = 'https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv'\n",
    "villagers_df = pd.read_csv(url)\n",
    "# Assuming df is your DataFrame\n",
    "missing_values_villagers = villagers_df.isna().sum()\n",
    "print(missing_values_villagers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ee6fbb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "villagers_df['id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "231af157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "380"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "villagers_df['song'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afd85fe",
   "metadata": {},
   "source": [
    "there is 1 missing value from 'id' and 11 missing values from song. \n",
    "therefore, the efficient way to approach removing the null values is to use df.dropna() to drop the 1 null value from the 'id' column in which we would only lose 0.2% of data in the entire dataset.\n",
    "\n",
    "with only 2.89% missing values, deleting the entire 'song' column may be too drastic unless the column is irrelevant to your analysis. \n",
    "if it is irrelavent to our analysis, we can use del df['song'] to delete the 'song' column.\n",
    "if it is relevant to the analysis, then we would be loosing 97.11% of non-missing vlaues if we deleted the entire column. \n",
    "in the case that we want to keep as much non-missing values in our dataset (efficiently removing missing data) we can use df.dropna() again for the song column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb1c1aaf",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_n</th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>species</th>\n",
       "      <th>birthday</th>\n",
       "      <th>personality</th>\n",
       "      <th>phrase</th>\n",
       "      <th>full_id</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Admiral</td>\n",
       "      <td>male</td>\n",
       "      <td>bird</td>\n",
       "      <td>1-27</td>\n",
       "      <td>cranky</td>\n",
       "      <td>aye aye</td>\n",
       "      <td>villager-admiral</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Agent S</td>\n",
       "      <td>female</td>\n",
       "      <td>squirrel</td>\n",
       "      <td>7-2</td>\n",
       "      <td>peppy</td>\n",
       "      <td>sidekick</td>\n",
       "      <td>villager-agent-s</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Agnes</td>\n",
       "      <td>female</td>\n",
       "      <td>pig</td>\n",
       "      <td>4-21</td>\n",
       "      <td>uchi</td>\n",
       "      <td>snuffle</td>\n",
       "      <td>villager-agnes</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>Al</td>\n",
       "      <td>male</td>\n",
       "      <td>gorilla</td>\n",
       "      <td>10-18</td>\n",
       "      <td>lazy</td>\n",
       "      <td>Ayyeeee</td>\n",
       "      <td>villager-al</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>Alfonso</td>\n",
       "      <td>male</td>\n",
       "      <td>alligator</td>\n",
       "      <td>6-9</td>\n",
       "      <td>lazy</td>\n",
       "      <td>it'sa me</td>\n",
       "      <td>villager-alfonso</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>475</td>\n",
       "      <td>Winnie</td>\n",
       "      <td>female</td>\n",
       "      <td>horse</td>\n",
       "      <td>1-31</td>\n",
       "      <td>peppy</td>\n",
       "      <td>hay-OK</td>\n",
       "      <td>villager-winnie</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>477</td>\n",
       "      <td>Wolfgang</td>\n",
       "      <td>male</td>\n",
       "      <td>wolf</td>\n",
       "      <td>11-25</td>\n",
       "      <td>cranky</td>\n",
       "      <td>snarrrl</td>\n",
       "      <td>villager-wolfgang</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>480</td>\n",
       "      <td>Yuka</td>\n",
       "      <td>female</td>\n",
       "      <td>koala</td>\n",
       "      <td>7-20</td>\n",
       "      <td>snooty</td>\n",
       "      <td>tsk tsk</td>\n",
       "      <td>villager-yuka</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>481</td>\n",
       "      <td>Zell</td>\n",
       "      <td>male</td>\n",
       "      <td>deer</td>\n",
       "      <td>6-7</td>\n",
       "      <td>smug</td>\n",
       "      <td>pronk</td>\n",
       "      <td>villager-zell</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>483</td>\n",
       "      <td>Zucker</td>\n",
       "      <td>male</td>\n",
       "      <td>octopus</td>\n",
       "      <td>3-8</td>\n",
       "      <td>lazy</td>\n",
       "      <td>bloop</td>\n",
       "      <td>villager-zucker</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>391 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     row_n      name  gender    species birthday personality    phrase  \\\n",
       "0        2   Admiral    male       bird     1-27      cranky   aye aye   \n",
       "1        3   Agent S  female   squirrel      7-2       peppy  sidekick   \n",
       "2        4     Agnes  female        pig     4-21        uchi   snuffle   \n",
       "3        6        Al    male    gorilla    10-18        lazy   Ayyeeee   \n",
       "4        7   Alfonso    male  alligator      6-9        lazy  it'sa me   \n",
       "..     ...       ...     ...        ...      ...         ...       ...   \n",
       "386    475    Winnie  female      horse     1-31       peppy    hay-OK   \n",
       "387    477  Wolfgang    male       wolf    11-25      cranky   snarrrl   \n",
       "388    480      Yuka  female      koala     7-20      snooty   tsk tsk   \n",
       "389    481      Zell    male       deer      6-7        smug     pronk   \n",
       "390    483    Zucker    male    octopus      3-8        lazy     bloop   \n",
       "\n",
       "               full_id                                                url  \n",
       "0     villager-admiral  https://villagerdb.com/images/villagers/thumb/...  \n",
       "1     villager-agent-s  https://villagerdb.com/images/villagers/thumb/...  \n",
       "2       villager-agnes  https://villagerdb.com/images/villagers/thumb/...  \n",
       "3          villager-al  https://villagerdb.com/images/villagers/thumb/...  \n",
       "4     villager-alfonso  https://villagerdb.com/images/villagers/thumb/...  \n",
       "..                 ...                                                ...  \n",
       "386    villager-winnie  https://villagerdb.com/images/villagers/thumb/...  \n",
       "387  villager-wolfgang  https://villagerdb.com/images/villagers/thumb/...  \n",
       "388      villager-yuka  https://villagerdb.com/images/villagers/thumb/...  \n",
       "389      villager-zell  https://villagerdb.com/images/villagers/thumb/...  \n",
       "390    villager-zucker  https://villagerdb.com/images/villagers/thumb/...  \n",
       "\n",
       "[391 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove rows with missing data\n",
    "import pandas as pd\n",
    "url = 'https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv'\n",
    "villagers_df = pd.read_csv(url)\n",
    "\n",
    "# delete\n",
    "\n",
    "# Drop rows with any missing data\n",
    "villagers_df.dropna()\n",
    "\n",
    "# Drop columns with any missing data\n",
    "villagers_df.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8f928e",
   "metadata": {},
   "source": [
    "# chatbot history + summary\n",
    "https://chatgpt.com/share/4a81a680-2697-4c22-9fc1-d504e9e02706\n",
    "We discussed handling missing values in the `song` column of your villagers dataset, considering whether to drop rows, impute, or delete the column.\n",
    "\n",
    "https://chatgpt.com/share/1213ae67-7f37-42a1-983a-2adba5727130 \n",
    "\n",
    "Here's a summary of our interaction so far:\n",
    "\n",
    "    Introduction to df.dropna():\n",
    "        We discussed when to use df.dropna() for cleaning rows or columns that contain missing values. This is useful when preparing datasets for analysis or ensuring completeness in machine learning models.\n",
    "\n",
    "    Context of Your Dataset:\n",
    "        Your dataset from TidyTuesday contains information on villagers. We explored how df.dropna() can be used in this context to remove rows or columns with missing values in specific fields like species, personality, or birthday.\n",
    "\n",
    "    Examples of Using df.dropna() in Your Dataset:\n",
    "        Drop rows with missing values in key columns (e.g., species, personality, birthday).\n",
    "        Remove columns with excessive missing data, such as dropping a column with too many NaNs (e.g., catchphrase).\n",
    "        Drop columns based on a threshold (e.g., if more than 50% of a column's values are missing).\n",
    "\n",
    "    When to Use del df['col']:\n",
    "        We explored when to use del df['col'] to remove irrelevant or redundant columns:\n",
    "            Remove irrelevant columns (e.g., file_name if you don’t need file paths for analysis).\n",
    "            Remove redundant columns (e.g., birthday_month if the full birthday column is already present).\n",
    "            Remove columns with privacy concerns (e.g., real_name).\n",
    "            Remove columns with excessive missing values or that don’t contribute to your analysis (e.g., catchphrase if it’s missing a lot of data).\n",
    "            Simplify the dataset to focus on key attributes (e.g., removing gender if it’s irrelevant to your analysis).\n",
    "\n",
    "Would you like further clarification on any of these topics or specific assistance with your dataset?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8866757d",
   "metadata": {},
   "source": [
    "# 8.1 demonstrate what groupby does\n",
    "The df.groupby(\"col1\")[\"col2\"].describe() function groups the data by the unique values in the column col1 and selects the col2 values. It then generates summary statistics for the selected column, col2, such as count, mean, standard deviation, min, max, 25%, 50%, and 75% percentiles. \n",
    "\n",
    "In the example in the cell below summary statistics for 'age' are calculated seperately for each group of col 1 'survived'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "579ce92b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>survived</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>424.0</td>\n",
       "      <td>30.626179</td>\n",
       "      <td>14.172110</td>\n",
       "      <td>1.00</td>\n",
       "      <td>21.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>290.0</td>\n",
       "      <td>28.343690</td>\n",
       "      <td>14.950952</td>\n",
       "      <td>0.42</td>\n",
       "      <td>19.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count       mean        std   min   25%   50%   75%   max\n",
       "survived                                                           \n",
       "0         424.0  30.626179  14.172110  1.00  21.0  28.0  39.0  74.0\n",
       "1         290.0  28.343690  14.950952  0.42  19.0  28.0  36.0  80.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv'\n",
    "t_df = pd.read_csv(url)\n",
    "\n",
    "#Group by 'survived' and describe the 'age' column. 0 means did not survive, 1 means survived\n",
    "t_df.groupby('survived')['age'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e48b58",
   "metadata": {},
   "source": [
    "424 passengers did not survive, the mean ages of the passengers who didn't survive is 30.6yrs, with a std of 14.2yrs, minimum age of 1, max age of 74, 25% of the passengers who didn't survive were younger than 21, 75% of the passengers who didn't survive were over 39.\n",
    "\n",
    "290 passengers did survive, with a mean age of 28.3yrs, std of 14.95yrs, minimum age of 0.42yrs, max age of 80yrs, 25% of survivors were younger than 19, 75% of survivors were older than 36."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0b80dd",
   "metadata": {},
   "source": [
    "# chatbot history + summary\n",
    "https://chatgpt.com/share/a805d037-609f-42b9-823e-d21f5286b82e\n",
    "We discussed the differences between `df.describe()` and `df.groupby().describe()` in pandas. `df.describe()` provides summary statistics for the entire DataFrame, while `df.groupby().describe()` gives summary statistics for each group defined by a `groupby` operation. We then focused on the output of `t_df.groupby('survived')['age'].describe()`, explaining that percentiles (25th, 50th, and 75th) indicate the distribution of ages within each survival group, helping to understand if age influenced survival rates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2175e57",
   "metadata": {},
   "source": [
    "# 8.2 df.describe() vs df.groupby('col1')['col2'].describe()\n",
    "\n",
    "the count values produced by df.groupby(\"col1\")[\"col2\"].describe() and df.describe() are different because of how the data is treated in each case. both functions ignore the null/NaN values and provide summary statistics.\n",
    "\n",
    "df.groupby('col1')['col2'].describe function is more specific as it groups the count by comparing the non-missing values of one column with the unique values in another column.\n",
    "\n",
    "df.describe counts the non-missing values of the entire dataset rather than specific columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9248f4",
   "metadata": {},
   "source": [
    "# value counts using df.describe() \n",
    "df.describe() performs a calculation is done based on the entire dataset. It counts the number of non-missing values across the entire column and does not consider any grouping. This function creates one set of summary statistics for the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38189b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare',\n",
       "       'embarked', 'class', 'who', 'adult_male', 'deck', 'embark_town',\n",
       "       'alive', 'alone'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1309b436",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         survived      pclass         age       sibsp       parch        fare\n",
       "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
       "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
       "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
       "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
       "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
       "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
       "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "t_url= \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "t_df = pd.read_csv(t_url)\n",
    "t_df.describe() \n",
    "# The output summary statistics for the entire dataset, without grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77144f2",
   "metadata": {},
   "source": [
    "# value counts using df.groupby(\"col1\")[\"col2\"].describe()\n",
    "the count values produced by df.groupby(\"col1\")[\"col2\"].describe() are made by grouping the data based on the number of non-missing (NaN) values in col2 for each unique group in col1 to calculate the summary statistics within each group. \n",
    "\n",
    "unlike df.describe() which provides overall summary statistics for the entire dataset, df.groupby('col1')['col2'].describe() gives group-specific statistics (e.g., mean, median, min, max, etc.) for col2 within each group of col1. \n",
    "\n",
    "by focusing on counting non-missing values within a each group, it provides a count per group. \n",
    "\n",
    "this helps compare the statistics across different groups.\n",
    "\n",
    "in the cell below, you can see how df.groupby(\"col1\")[\"col2\"].describe() shows how many valid survivors values are there for each gender in the Titanic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "391c3257",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>314.0</td>\n",
       "      <td>0.742038</td>\n",
       "      <td>0.438211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>577.0</td>\n",
       "      <td>0.188908</td>\n",
       "      <td>0.391775</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count      mean       std  min  25%  50%  75%  max\n",
       "sex                                                       \n",
       "female  314.0  0.742038  0.438211  0.0  0.0  1.0  1.0  1.0\n",
       "male    577.0  0.188908  0.391775  0.0  0.0  0.0  0.0  1.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_df.groupby('sex')['survived'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0b92b4",
   "metadata": {},
   "source": [
    "Count for females = 314 shows that there are 314 non-missing age values for female passengers.\n",
    "Count for males = 577 shows that there are 577 non-missing age values for male passengers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db575a60",
   "metadata": {},
   "source": [
    "# how the counts differ \n",
    "in df['age'].describe(), the count is 714 because it considers the total number of non-missing age values across all passengers.\n",
    "\n",
    "in df.groupby('sex')['survived'].describe(), the grouped count differs from df.describe() because the counts are now being split between the two groups 'sex' and 'survived' where each group's count reflects the number of non-missing age values within that group (165 females and 360 males)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad9afac",
   "metadata": {},
   "source": [
    "# chatbot history + summary\n",
    "https://chatgpt.com/share/9acfd934-c5de-4fc8-873c-9a4704bae3f2\n",
    "We discussed how `df.groupby('col1')['col2'].describe()` works in the context of the Titanic dataset and explored how it differs from `df.describe()`. We covered:\n",
    "\n",
    "1. **`groupby()` vs `describe()`**:\n",
    "   - `groupby().describe()` provides detailed summary statistics (mean, median, quartiles, etc.) for each group (e.g., `sex`), while `describe()` gives overall statistics for the entire dataset or a column.\n",
    "   - `groupby().count()` shows non-missing values within each group, while `describe()` provides statistics for the whole dataset, ignoring missing values.\n",
    "   \n",
    "2. **Advantages of `groupby().describe()`**:\n",
    "   - It provides **group-specific statistics**, reveals **patterns across groups**, and handles missing values automatically, making it great for exploratory data analysis.\n",
    "\n",
    "The key takeaway is that `groupby().describe()` offers more detailed insights into your dataset by allowing you to compare statistics across different groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead49345",
   "metadata": {},
   "source": [
    "# 8.3 make errors on purpose, use chat and google to troubleshoot; determine which is better at troubleshooting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd00eb2a",
   "metadata": {},
   "source": [
    "# A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7a41165",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# forget to include import pandas as pd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m t_url\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m t_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(t_url)\n\u001b[1;32m      4\u001b[0m t_df\u001b[38;5;241m.\u001b[39mdescribe()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# forget to include import pandas as pd\n",
    "t_url= \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "t_df = pd.read_csv(t_url)\n",
    "t_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcb0b568",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         survived      pclass         age       sibsp       parch        fare\n",
       "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
       "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
       "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
       "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
       "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
       "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
       "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fix the issue above by importing pandas as pd\n",
    "import pandas as pd\n",
    "t_url= \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "t_df = pd.read_csv(t_url)\n",
    "t_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01ff96b",
   "metadata": {},
   "source": [
    "- chat took time to generate, google search loaded faster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0243e9",
   "metadata": {},
   "source": [
    "# B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81932b71",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m t_url\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanics.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m t_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m t_df\u001b[38;5;241m.\u001b[39mshape()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/common.py:718\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    715\u001b[0m     codecs\u001b[38;5;241m.\u001b[39mlookup_error(errors)\n\u001b[1;32m    717\u001b[0m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[0;32m--> 718\u001b[0m ioargs \u001b[38;5;241m=\u001b[39m \u001b[43m_get_filepath_or_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    726\u001b[0m handle \u001b[38;5;241m=\u001b[39m ioargs\u001b[38;5;241m.\u001b[39mfilepath_or_buffer\n\u001b[1;32m    727\u001b[0m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/common.py:372\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;66;03m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[1;32m    371\u001b[0m req_info \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(filepath_or_buffer, headers\u001b[38;5;241m=\u001b[39mstorage_options)\n\u001b[0;32m--> 372\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq_info\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m req:\n\u001b[1;32m    373\u001b[0m     content_encoding \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m content_encoding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    375\u001b[0m         \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/common.py:274\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;124;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;124;03mthe stdlib.\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m\n\u001b[0;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[1;32m    524\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 525\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[0;32m--> 634\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:563\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[1;32m    562\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[0;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:643\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[0;32m--> 643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "# type file name wrong\n",
    "import pandas as pd\n",
    "t_url= \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanics.csv\"\n",
    "t_df = pd.read_csv(t_url)\n",
    "t_df.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec4b5bfd",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         survived      pclass         age       sibsp       parch        fare\n",
       "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
       "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
       "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
       "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
       "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
       "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
       "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fix issue above by checking for typographical errors (mispelling file names)\n",
    "import pandas as pd\n",
    "t_url= \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "t_df = pd.read_csv(t_url)\n",
    "t_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2ce04e",
   "metadata": {},
   "source": [
    "- chat offered multiple different solutions to different sources of problems that could cause the error message for B\n",
    "- google search directed me to stackoverflow which offered me one solution to the exact problem in B: mispelling the file name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b9351c",
   "metadata": {},
   "source": [
    "# C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "597ea373",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DF' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# use a dataframe that hasn't been assigned/defined yet\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mDF\u001b[49m\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol1\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol2\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DF' is not defined"
     ]
    }
   ],
   "source": [
    "# use a dataframe that hasn't been assigned/defined yet\n",
    "\n",
    "DF.groupby(\"col1\")[\"col2\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73da2d47",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         survived      pclass         age       sibsp       parch        fare\n",
       "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
       "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
       "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
       "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
       "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
       "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
       "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fix by using a defined dataframe like 't_df' or alternatively defining the variable 'DF' \n",
    "# i will be using 't_df' since i've defined it previously\n",
    "import pandas as pd\n",
    "t_url= \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "t_df = pd.read_csv(t_url)\n",
    "t_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5710fd1",
   "metadata": {},
   "source": [
    "- chat offered multiple different solutions to different sources of problems that could cause the error message for c\n",
    "- google search directed me to stackoverflow which offered me one solution to the exact problem in c: using an undefined df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7867a644",
   "metadata": {},
   "source": [
    "# D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aac3c281",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'(' was never closed (3285048580.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[8], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    t_df = pd.read_csv(t_url\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m '(' was never closed\n"
     ]
    }
   ],
   "source": [
    "# forget a parentheses\n",
    "import pandas as pd\n",
    "t_url= \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "t_df = pd.read_csv(t_url\n",
    "t_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12451c63",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         survived      pclass         age       sibsp       parch        fare\n",
       "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
       "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
       "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
       "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
       "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
       "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
       "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fix by checking for missing characters (i.e. parentheses)\n",
    "import pandas as pd\n",
    "t_url= \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "t_df = pd.read_csv(t_url)\n",
    "t_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5eecfba",
   "metadata": {},
   "source": [
    "- chat offered multiple different solutions to different sources of problems that could cause the error message for D\n",
    "- google search directed me to stackoverflow which offered me one solution to the exact problem in D: forgetting a parentheses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e385d88",
   "metadata": {},
   "source": [
    "# E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc92ae50",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SeriesGroupBy' object has no attribute 'describleyaya'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m t_url\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m t_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(t_url)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mt_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msex\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdescribleyaya\u001b[49m()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1312\u001b[0m, in \u001b[0;36mGroupBy.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m   1309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj:\n\u001b[1;32m   1310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[attr]\n\u001b[0;32m-> 1312\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1313\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1314\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SeriesGroupBy' object has no attribute 'describleyaya'"
     ]
    }
   ],
   "source": [
    "# mistype one of the names of the chained functions with the code\n",
    "import pandas as pd\n",
    "t_url= \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "t_df = pd.read_csv(t_url)\n",
    "t_df.groupby(\"sex\")[\"age\"].describleyaya()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fc97db2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>261.0</td>\n",
       "      <td>27.915709</td>\n",
       "      <td>14.110146</td>\n",
       "      <td>0.75</td>\n",
       "      <td>18.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>453.0</td>\n",
       "      <td>30.726645</td>\n",
       "      <td>14.678201</td>\n",
       "      <td>0.42</td>\n",
       "      <td>21.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count       mean        std   min   25%   50%   75%   max\n",
       "sex                                                              \n",
       "female  261.0  27.915709  14.110146  0.75  18.0  27.0  37.0  63.0\n",
       "male    453.0  30.726645  14.678201  0.42  21.0  29.0  39.0  80.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fix by checking for typographical errors\n",
    "import pandas as pd\n",
    "t_url= \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "t_df = pd.read_csv(t_url)\n",
    "t_df.groupby(\"sex\")[\"age\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d846714",
   "metadata": {},
   "source": [
    "- chat took time to generate, gave me mutliple different solutions and examples\n",
    "- google search loaded faster, provided one solution that was specific to my error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93461fb",
   "metadata": {},
   "source": [
    "# F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d04d5a3a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Sex'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m t_url\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m t_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(t_url)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mt_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSex\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/frame.py:8869\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   8866\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   8867\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 8869\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   8870\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8871\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8872\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8873\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8874\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8875\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8876\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8877\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8878\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8879\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1278\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[1;32m   1277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1278\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1281\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[1;32m   1289\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mgroupings):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/groupby/grouper.py:1009\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[1;32m   1007\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1008\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1009\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Sex'"
     ]
    }
   ],
   "source": [
    "# use a column name that's not in the titanic dataset, python is case sensitive so adding a capital-letter will cause a problem\n",
    "# 'Sex' instead of 'sex'\n",
    "import pandas as pd\n",
    "t_url= \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "t_df = pd.read_csv(t_url)\n",
    "t_df.groupby(\"Sex\")[\"age\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ac2598c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>261.0</td>\n",
       "      <td>27.915709</td>\n",
       "      <td>14.110146</td>\n",
       "      <td>0.75</td>\n",
       "      <td>18.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>453.0</td>\n",
       "      <td>30.726645</td>\n",
       "      <td>14.678201</td>\n",
       "      <td>0.42</td>\n",
       "      <td>21.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count       mean        std   min   25%   50%   75%   max\n",
       "sex                                                              \n",
       "female  261.0  27.915709  14.110146  0.75  18.0  27.0  37.0  63.0\n",
       "male    453.0  30.726645  14.678201  0.42  21.0  29.0  39.0  80.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fix by changing 'Sex' which isn't a column name in the dataset to 'sex' which is a column name in the dataset\n",
    "# since python is case sensitive, this caused an error when running the code\n",
    "import pandas as pd\n",
    "t_url= \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "t_df = pd.read_csv(t_url)\n",
    "t_df.groupby(\"sex\")[\"age\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fe104be",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Column not found: Age'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m t_url\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m t_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(t_url)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mt_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msex\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAge\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mdescribe()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/groupby/generic.py:1964\u001b[0m, in \u001b[0;36mDataFrameGroupBy.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1958\u001b[0m     \u001b[38;5;66;03m# if len == 1, then it becomes a SeriesGroupBy and this is actually\u001b[39;00m\n\u001b[1;32m   1959\u001b[0m     \u001b[38;5;66;03m# valid syntax, so don't raise\u001b[39;00m\n\u001b[1;32m   1960\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1961\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot subset columns with a tuple with more than one element. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1962\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse a list instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1963\u001b[0m     )\n\u001b[0;32m-> 1964\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/base.py:244\u001b[0m, in \u001b[0;36mSelectionMixin.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj:\n\u001b[0;32m--> 244\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    245\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj[key]\u001b[38;5;241m.\u001b[39mndim\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gotitem(key, ndim\u001b[38;5;241m=\u001b[39mndim)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Column not found: Age'"
     ]
    }
   ],
   "source": [
    "# same thing but using 'Age' instead of 'age'\n",
    "import pandas as pd\n",
    "t_url= \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "t_df = pd.read_csv(t_url)\n",
    "t_df.groupby(\"sex\")[\"Age\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a0ea908",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>261.0</td>\n",
       "      <td>27.915709</td>\n",
       "      <td>14.110146</td>\n",
       "      <td>0.75</td>\n",
       "      <td>18.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>453.0</td>\n",
       "      <td>30.726645</td>\n",
       "      <td>14.678201</td>\n",
       "      <td>0.42</td>\n",
       "      <td>21.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count       mean        std   min   25%   50%   75%   max\n",
       "sex                                                              \n",
       "female  261.0  27.915709  14.110146  0.75  18.0  27.0  37.0  63.0\n",
       "male    453.0  30.726645  14.678201  0.42  21.0  29.0  39.0  80.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fix by changing 'Age' which isn't a column name in the dataset to 'age' which is a column name in the dataset\n",
    "# since python is case sensitive, this caused an error when running the code\n",
    "import pandas as pd\n",
    "t_url= \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "t_df = pd.read_csv(t_url)\n",
    "t_df.groupby(\"sex\")[\"age\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a696f936",
   "metadata": {},
   "source": [
    "- chat's loading time was similar to google search\n",
    "- both gave me the same solution to the error in F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717b59bf",
   "metadata": {},
   "source": [
    "# G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0097aaef",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'age' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m t_url\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m t_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(t_url)\n\u001b[0;32m----> 5\u001b[0m t_df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msex\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[43mage\u001b[49m]\u001b[38;5;241m.\u001b[39mdescribe()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'age' is not defined"
     ]
    }
   ],
   "source": [
    "# forget to put the column name as a string\n",
    "import pandas as pd\n",
    "t_url= \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "t_df = pd.read_csv(t_url)\n",
    "t_df.groupby(\"sex\")[age].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbfa8886",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>261.0</td>\n",
       "      <td>27.915709</td>\n",
       "      <td>14.110146</td>\n",
       "      <td>0.75</td>\n",
       "      <td>18.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>453.0</td>\n",
       "      <td>30.726645</td>\n",
       "      <td>14.678201</td>\n",
       "      <td>0.42</td>\n",
       "      <td>21.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count       mean        std   min   25%   50%   75%   max\n",
       "sex                                                              \n",
       "female  261.0  27.915709  14.110146  0.75  18.0  27.0  37.0  63.0\n",
       "male    453.0  30.726645  14.678201  0.42  21.0  29.0  39.0  80.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fix by making the column name into a string so the function can be called\n",
    "import pandas as pd\n",
    "t_url= \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "t_df = pd.read_csv(t_url)\n",
    "t_df.groupby(\"sex\")[\"age\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576fa5bb",
   "metadata": {},
   "source": [
    "- both chatGPT & google search gave me similiar wokring code in comparable loading times\n",
    "- however, stackoverflow (a search result) gave me a better reason for why forgetting to put the column name as a string will produce this error "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6ad95b",
   "metadata": {},
   "source": [
    "# conclusion: chat or google (stackoverflow)\n",
    "In my opinion, both ChatGPT and Google search were equally fast in giving me a solution, although I did spend a decent amount of time cross-checking every answer from ChatGPT with code/solutions people have posted on sites like StackOverflow.\n",
    "\n",
    "On sites like StackOverflow or Medium, there are comments and you can see users' opinions or tips/tricks for troubleshooting and understanding the problems I had. This makes me trust these solutions from Google search more than blindly executing code from ChatGPT, which needed trial and error to see if the generated code will actually help.\n",
    "\n",
    "\n",
    "# chatbot history + summaries:\n",
    "https://chatgpt.com/share/bb07f3bc-ebc2-42fd-b6ae-365fd283ea67\n",
    "Here's a brief summary of our interaction:\n",
    "\n",
    "1. **Error Handling**:\n",
    "   - **`NameError: name 'pd' is not defined`**: You needed to import the `pandas` library using `import pandas as pd`.\n",
    "   - **`NameError: name 'titanics' is not defined`**: There was a typo; it should be `t_df`, not `titanics`.\n",
    "   - **`HTTPError: HTTP Error 404: Not Found`**: The URL for the Titanic dataset was incorrect or the file was not available.\n",
    "   - **`SyntaxError: '(' was never closed`**: There was an unmatched parenthesis in the `pd.read_csv()` function call.\n",
    "   - **`KeyError` issues**: Incorrect column names were used; column names need to be verified and matched correctly.\n",
    "   - **`AttributeError`**: A typo in method name (`describleyaya` instead of `describe()`).\n",
    "   - **`NameError: name 'age' is not defined`**: Column names should be in quotes when referencing them.\n",
    "\n",
    "2. **Solutions Provided**:\n",
    "   - Ensured correct import statements and function usage.\n",
    "   - Corrected column names and method names based on dataset structure.\n",
    "   - Recommended checking column names using `print(t_df.columns)` to resolve issues.\n",
    "\n",
    "Let me know if there's anything else you need help with!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73180828",
   "metadata": {},
   "source": [
    "# 9 \n",
    "yes i have taken a look at the wiki-textbook and piazza."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9114742",
   "metadata": {},
   "source": [
    "# other chatbot history links and summaries\n",
    "https://chatgpt.com/share/1213ae67-7f37-42a1-983a-2adba5727130 --> df.dropna vs del df['col']\n",
    "\n",
    "Here's a summary of our interaction:\n",
    "\n",
    "1. **Question on `df.shape` and `df.describe()`**:\n",
    "   - You asked about the difference between `df.shape` and `df.describe()`.\n",
    "   - I explained that `df.shape` returns the dimensions of the DataFrame (as a tuple: number of rows, number of columns), while `df.describe()` provides summary statistics for the numerical columns of the DataFrame.\n",
    "\n",
    "2. **Attributes vs Methods**:\n",
    "   - You asked how these relate to attributes and methods.\n",
    "   - I explained that:\n",
    "     - **`df.shape` is an attribute** because it represents a property of the DataFrame and does not require parentheses.\n",
    "     - **`df.describe()` is a method** because it performs a calculation and needs to be called with parentheses.\n",
    "\n",
    "Let me know if you'd like more information or have any further questions!\n",
    "\n",
    "Here's a summary of our interaction so far:\n",
    "\n",
    "1. You mentioned you are working with a dataset about characters from *Animal Crossing* from the TidyTuesday project (specifically from May 5, 2020).\n",
    "2. You asked for details on the dataset structure, including how many rows and columns it has.\n",
    "3. I initially tried to load and analyze the dataset but was unable to access the tool for more advanced operations. I then provided you with a Python code snippet to find the number of rows and columns in the dataset yourself.\n",
    "\n",
    "Let me know if you'd like further assistance!\n",
    "\n",
    "Here's a summary of our interaction:\n",
    "\n",
    "1. **Dataset Exploration**:\n",
    "   - You are working with a dataset from the TidyTuesday project (May 5, 2020), focused on villagers.\n",
    "   - We discussed key terms like **observations** (rows) and **variables** (columns), focusing on how they relate to your dataset.\n",
    "\n",
    "2. **Inspecting the Dataset**:\n",
    "   - You asked about the size of the dataset, which we explored using `df.shape` (which gave 391 rows and 11 columns).\n",
    "   - We also examined how `df.describe()` provides a summary of the numeric columns by default and how it differs from `df.shape` in terms of analyzed columns and reported counts (non-missing values).\n",
    "\n",
    "3. **Basic Data Summary**:\n",
    "   - I provided steps to check for missing values, display the column names, and perform simple summarizations like `df.describe(include='all')`, `df.info()`, and `df.isnull().sum()`.\n",
    "\n",
    "4. **Comparing `df.shape` vs. `df.describe()`**:\n",
    "   - We discussed how `df.shape` reports the total size, while `df.describe()` reports only non-missing values and typically only analyzes numeric columns unless specified otherwise (`include='all'`).\n",
    "\n",
    "Throughout our interaction, we focused on understanding the structure and content of the villagers dataset, preparing you to summarize and analyze it efficiently.\n",
    "\n",
    "Let me know if you'd like further assistance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18b52f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
